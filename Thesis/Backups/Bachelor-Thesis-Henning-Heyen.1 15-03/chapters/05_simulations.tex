
\chapter{Simulations}\label{chapter:simulations}

In this chapter, I want to give an intuition for the results on no-regret convergence in finite games discussed in chapter \ref{chapter:literatureReview}. I have implemented both, \textit{projected online gradients ascent} (POGA) and \textit{entropic gradient ascent} (EGA). As expected, both algorithms show very similar behavior. The \textit{steep entropic regularizer} used in EGA slightly reshaped the players' trajectories in comparison to the common \textit{Euclidean regularizer} in POGA. In terms of convergence, however, both behave the same. For that reason, I might show plots of only one algorithm. In the vector field plots, the black star ($\bigstar$) will denote an interior Nash equilibrium while the black dot ({\Large\textbullet}) stands for a pure Nash equilibrium. The orange dot ({\color[HTML]{E37222}\Large\textbullet}) denotes an initial strategy profile. \\

As the results suggest, I found Nash convergence in frequencies in two-player zero-sum games with an interior equilibrium and last-iterate convergence in games where strict Nash equilibria exist. I have limited myself to 2x2 and 3x3 bimatrix games, as higher-dimensional games with more than two players are hard to illustrate. Therefore we have $\mathcal{N} = \{1,2\}$ throughout this chapter. The outcome of no-regret learning depends on the type of game and the type of equilibria. The chapter is structured accordingly. 

\section{Unique Fully Mixed Nash Equilibrium}\label{section:uniqueMixedNashEquilibrium}

Let us first consider games that yield an interior, or equivalently fully mixed, Nash equilibrium. In general, we would expect the algorithms' trajectories not to converge because there exists no pure and therefore no strict Nash equilibrium. In particular as stated in proposition \ref{prop:noInteriorStable}, no fully mixed Nash equilibrium can be asymptotically stable and therefore no interior equilibrium can be attracting. However, at least in two-player zero-sum games, we expect the empirical frequency of play, i.e. time-averaged strategies, to converge to the interior Nash equilibrium (proposition \ref{prop:empiricalFrequencyConvergence}).

\subsection{Matching Pennies}\label{subsection:machtingPennies}

Matching Pennies is a simple two-player zero-sum game. Both players choose between \textit{Heads} and \textit{Tails}, and if they match, then the row player wins, and if they mismatch, the column player wins. The payoff is set accordingly as in table \ref{tab:payoffMachtingPennies}. 

\begin{table}[H]\centering
\setlength{\extrarowheight}{2pt}
\begin{tabular}{cc|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$Heads$}  & \multicolumn{1}{c}{$Tails$} \\\cline{3-4}
  & $Heads$ & $1,-1$ & $-1,1$ \\\cline{3-4}
  & $Tails$ & $-1,1$ & $1,-1$ \\\cline{3-4}
\end{tabular}\caption{\label{tab:payoffMachtingPennies}payoff matrix Matching Pennies}
\end{table}

There is only a single fully mixed Nash equilibrium, i.e. when both players choose \textit{Heads} and \textit{Tails} equally likely. 

\begin{equation*}
    x_{i}^{*} = (1/2,1/2) \qquad \forall i \in \mathcal{N}
\end{equation*}

As stated in proposition \ref{prop:noInteriorStable} no fully mixed strategy, and therefore no interior Nash equilibrium, can be asymptotically stable under \ref{equ:FTRL} algorithms. Since \ref{equ:FTRL} can only converge to stable states or strict Nash equilibria equivalently (see proposition \ref{prop:StrictStableEquivalent}), for both EGA and POGA, the induced sequence of play fails to converge. Both exhibit cyclic behavior around the unique MNE as illustrated in the figure \ref{fig:PenniesStream1}. As we can see, using entropic regularization, the projections always lead to interior strategies, whereas for Euclidean regularization, strategies are potentially projected to the boundary. Note that $x_{i,Tails}$ is implicitly given by $1 - x_{i,Heads}$.

\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Pennies1.png}
    \caption{POGA}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Pennies2.png}
    \caption{EGA}
\end{subfigure}
\caption{vector field in Matching Pennies}
\label{fig:PenniesStream1}
\end{figure}

The vector field might be misleading, as it looks like the algorithms cycle perfectly around the MNE but that would only hold for infinitesimal step size. \\

A closer examination of the specific trajectories, however, shows that actually for positive step size, they are repelled from the interior equilibrium as depicted in figure \ref{fig:PenniesDivergence}. Moreover, as mentioned earlier, in every 2x2 zero-sum game with interior equilibrium, trajectories diverge to the boundary under \ref{equ:FTRL} for all initial strategy profiles other than the equilibrium \cite{bailey}. \\

\begin{figure}[H]
 \captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Pennies5.png}
    \caption{POGA}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Pennies6.png}
    \caption{EGA}
\end{subfigure}
\caption{trajectories with initial strategies $x_{1}^0 = (\frac{1}{2},\frac{1}{2})$ and $x_{2}^0 = (\frac{2}{5},\frac{3}{5})$, $T = 200$, $\gamma = 0.3$}
\label{fig:PenniesDivergence}
\end{figure} 


As expected, the time-averaged trajectories, on the other hand, ultimately converge to the unique MNE. That happened independently from the initial strategies of the players. The amplitude of cycles dampens over time, as illustrated in figure \ref{fig:Pennies7}. That finding perfectly fits to proposition \ref{prop:empiricalFrequencyConvergence}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{logos/Pennies7.png}
    \caption{EGA empirical frequency of play in Matching Pennies, $\gamma = 0.1$}
    \label{fig:Pennies7}
\end{figure}


\subsection{Rock Paper Scissors}\label{subsection:rockPaperScissors}

One might think the convergence of empirical frequencies to the game's MNE is an artifact of its simple 2x2 structure, but I found similar behavior in Rock Paper Scissors, a 3x3 zero-sum game.

\begin{table}[H]\centering
\setlength{\extrarowheight}{2pt}
\begin{tabular}{cc|c|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$Rock$}  & \multicolumn{1}{c}{$Paper$}  & \multicolumn{1}{c}{$Scissors$} \\\cline{3-5}
            & $Rock$ & $0,0$ & $-1,1$ & $1,-1$ \\ \cline{3-5}
            & $Paper$ & $1,-1$ & $0,0$ & $-1,1$ \\\cline{3-5}
            & $Scissors$ & $-1,1$ & $1,-1$ & $0,0$ \\\cline{3-5}
\end{tabular}\caption{\label{tab:payoffRPS}payoff matrix Rock Paper Scissors}
\end{table}

The only Nash equilibrium that exists is the following fully mixed NE.

\begin{equation*}
    x_{i}^{*} = (1/3,1/3,1/3) \qquad \forall i \in \mathcal{N}
\end{equation*}

Both algorithms exhibit out-of-sync oscillating behavior. Also, the cyclic period and amplitude increase over time, corresponding to the repelling behavior we observed in Matching Pennies. The players essentially chase one another. An illustration of that behavior is shown in figure \ref{fig:RPSa}. Again, the empirical frequencies, on the other hand, converge to the game's interior Nash equilibrium as in figure \ref{fig:RPSb}. Note that the initial strategies are assigned randomly.

\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/RPS2.png}
    \caption{last-iterate}
    \label{fig:RPSa}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/RPS3.png}
    \caption{time-average}
    \label{fig:RPSb}
\end{subfigure}
\caption{EGA behavior in Rock Paper Scissors, $\gamma = 0.1$}
\label{fig:RPS}
\end{figure}


\subsection{Shapley Game}\label{subsection:shapleyGame}

The Shapley Game \cite{jafari} resembles that of Rock Paper Scissors. The difference is that it is not zero-sum but general-sum. In the payoff matrix (table \ref{tab:payoffShapley}), we can see that the utility of an action profile sometimes sums up to $1$ and sometimes to $0$. 

\begin{table}[H]\centering
\setlength{\extrarowheight}{2pt}
\begin{tabular}{cc|c|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$L$}  & \multicolumn{1}{c}{$C$}  & \multicolumn{1}{c}{$R$} \\\cline{3-5}
            & $T$ & $1,0$ & $0,1$ & $0,0$ \\ \cline{3-5}
            & $M$ & $0,0$ & $1,0$ & $0,1$ \\\cline{3-5}
            & $B$ & $0,1$ & $0,0$ & $1,0$ \\\cline{3-5}
\end{tabular}\caption{\label{tab:payoffShapley}payoff matrix Shapley Game}
\end{table}

The game's unique NE is the same fully mixed Nash equilibrium as in Rock Paper Scissors.

\begin{equation*}
    x_{i}^{*} = (1/3,1/3,1/3) \qquad \forall i \in \mathcal{N}
\end{equation*}

In this case, both EGA and POGA are non-convergent neither in weights nor in frequencies (figure \ref{fig:Shapley}). Again the weights cycle exponentially through the space of possible strategies. As far as frequencies are concerned, the amplitudes of the cycles do not dampen over time as they did in Matching Pennies or Rock Paper Scissors. They rather grow exponentially. In general sum games, like the Shapley Game, no regret dynamics seem to fail to converge generally. The same behaviour was found for \textit{fictitious play}, a simple \textit{best response} dynamic that is not a no-regret algorithm \cite{jafari}.


\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Shapley1.png}
    \caption{last-iterate}
    %\label{fig:POGDpseudocode}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Shapley2.png}
    \caption{time-average}
    %\label{fig:POGDpseudocode}
\end{subfigure}
\caption{divergent behavior of EGA in Shapley Game, $\gamma = 0.1$}
\label{fig:Shapley}
\end{figure}


\section{Unique Pure Nash Equilibrium}\label{section:uniquePureNashEquilibrium}

Next, we consider games with a unique pure Nash equilibrium. When the PNE is globally stable (definition \ref{def:stability}), then we expect the induced sequence of play to globally converge to the unique PNE (proposition \ref{prop:globalConvergence}). 

\subsection{Prisoner's Dilemma}\label{subsection:prisonersDilemma}

The example I would like to address is the famous Prisoner's Dilemma. The game works as follows. Two bank robbers have been arrested. They are separated from each other, and both can choose to stay silent or betray the other one by admitting the crime. When both stay silent, both are sent to prison for only one year. When both betray, then they get two years each. However, if one stays silent while the other betrays the one that stayed silent, goes to prison for three years while the other one is set free, see table \ref{tab:payoffPrisoners}.

\begin{table}[H]\centering
\setlength{\extrarowheight}{2pt}
\begin{tabular}{cc|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$Silent$}  & \multicolumn{1}{c}{$Betray$} \\\cline{3-4}
  & $Silent$ & $-1,-1$ & $-3,0$ \\\cline{3-4}
  & $Betray$ & $0,-3$ & $-2,-2$ \\\cline{3-4}
\end{tabular}\caption{\label{tab:payoffPrisoners}payoff matrix Prisoner's Dilemma}
\end{table}

The only Nash equilibrium is when both players choose \textit{Betray}. So there is no fully mixed Nash equilibrium but only one pure Nash equilibrium. 

\begin{equation*}
    x^{*} = (Betray,Betray) \qquad \textit{strict }\text{PNE}
\end{equation*}

Note that the PNE is also strict. Any unilateral deviation from the PNE would lead to a reduction in payoff. For instance, if the row player knows that the column player  chooses \textit{Betray}, then deviating from \textit{Betray} would decrease the row player's payoff, from $-2$ to $-3$. As the game is symmetric, the same holds for the column player. \\

Another observation is that for both players \textit{Silent} is strictly dominated by \textit{Betray} in the sense of equation \ref{equ:dominatedStrategy}. More precisely, no matter what the column players chooses to play, the row player is always better of playing \textit{Betray}, because $0 > -1$ and $-2 > -3$. Again, since the game is symmetric, the same holds for the column player. So by iteratively eliminating dominated strategies, we can solve this game. Such games are also called \textit{dominance solvable}. As stated in proposition \ref{prop:dominantedStrategiesExtinct} we expect that for both algorithms the dominated strategy \textit{Silent} becomes extinct, that means $x_{i,Silent}$ tends to $0$ as the number of iterations grows.  \\

Consider figure \ref{fig:Prisoner}. The blue region indicates strategies in the neighbourhood to the PNE that fulfill the inequality from the definition of stable states (\ref{def:stability}). We can see that the PNE is globally stable. As stated in proposition \ref{prop:globalConvergence}, \ref{equ:FTRL} converge globally to the globally stable equilibrium. As the vector field suggests, both POGA and EGA indeed converge globally to the game's unique PNE. Also, the dominated strategy \textit{Silent} becomes extinct. \\

Figure \ref{fig:Prisoner2} illustrates some specific trajectories that the algorithms take. We find that EGA does not reach the boundary as the projections always lead to interior strategies under entropic regularization. For OPGA, on the other hand, the Euclidean projections lead to strategies on the boundary at some point. Interestingly, using the same step size of $\gamma = 0.1$, POGA converges much faster than EGA. 


\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Prisoner2.png}
    \caption{POGA}
    %\label{fig:POGDpseudocode}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Prisoner3.png}
    \caption{EGA}
    %\label{fig:POGDpseudocode}
\end{subfigure}
\caption{vector field in Prisoner's Dilemma with stable neighbourhood w.r.t strict PNE}
\label{fig:Prisoner}
\end{figure}

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Prisoner4.png}
    \caption{POGA}
    %\label{fig:POGDpseudocode}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Prisoner5.png}
    \caption{EGA}
    %\label{fig:POGDpseudocode}
\end{subfigure}
\caption{trajectories with initial strategies $x_{1}^0 = (\frac{4}{5},\frac{1}{5})$ and $x_{2}^0 = (\frac{1}{2},\frac{1}{2})$, $T = 200$, $\gamma = 0.3$}
\label{fig:Prisoner2}
\end{figure}





\section{Mixed and Pure Nash Equilibria}\label{section:MixedandPureNashEquilibria}

In games where both fully mixed and pure Nash equilibria exist, we expect no-regret algorithms to converge to strict pure Nash equilibria solely. We will also see that as mentioned in proposition \ref{prop:noInteriorStable} interior equilibria are not asymptotically stable.

\subsection{Battle Of Sexes}\label{subsection:battleOfSexes}

Image a couple of two persons with different interests. One would prefer to watch a boxing fight, say the row player, and the other one prefers to go to a ballet, the column player. Nevertheless, they would rather spend time together than choose different events. There is no communication between both. The payoff is set accordingly as in table \ref{tab:payoffBattleOfSexes}.

\begin{table}[H]\centering
\setlength{\extrarowheight}{2pt}
\begin{tabular}{cc|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$Fight$}  & \multicolumn{1}{c}{$Ballet$} \\\cline{3-4}
  & $Fight$ & $3,2$ & $0,0$ \\\cline{3-4}
  & $Ballet$ & $0,0$ & $2,3$ \\\cline{3-4}
\end{tabular}\caption{\label{tab:payoffBattleOfSexes}payoff matrix Battle of Sexes}
\end{table}

There are two quite obvious pure Nash equilibria. One where both choose \textit{Fight}, and one where both choose \textit{Ballet}. Moreover, there is also a fully mixed Nash equilibrium, i.e. when both players randomize over the actions. In particular, the row player should choose \textit{Fight} with probability $3/5$ and \textit{Ballet} with $2/5$ and the column player should choose \textit{Fight} with $2/5$ and \textit{Ballet} with $3/5$. In formulas, we have the following Nash equilibria. 

\begin{description}\centering
    \item $x^{*} = (Fight,Fight) \qquad \textit{strict }\text{PNE}$
    \item $x^{*} = (Ballet,Ballet) \qquad \textit{strict }\text{PNE}$
    \item $x_{1}^* = (3/5,2/5) \qquad x_{2}^* = (2/5,3/5) \qquad \text{MNE}$
\end{description}

Note that again both PNE are strict in the sense of definition \ref{def:strictNE}. Neither the row player nor the column player can unilaterally deviate from a PNE without reducing its payoff. According to proposition \ref{prop:StrictStableEquivalent} that means both PNE are also stable states as defined in \ref{def:stability}. Then both PNE must also be locally attracting (proposition \ref{prop:localConvergence}). \\ 

Indeed, as shown in figure \ref{fig:BOS1}, both algorithms converge locally to the corresponding PNE. Notice how the stable regions of the PNE intersect. The attracting regions for both PNE can be implicitly derived from the vector field.


\begin{figure}[H]
%\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/BattleOfSexes1.png}
    \caption{POGA}
    %\label{fig:POGDpseudocode}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/BattleOfSexes2.png}
    \caption{EGA}
    %\label{fig:POGDpseudocode}
\end{subfigure}
\caption{vector field in Battle of Sexes,
the blue region indicates the stable neighbourhood w.r.t \textit{(Fight,Fight)} and the light green region w.r.t to \textit{(Ballet,Ballet)}, the dark green region is the intersection of both}
\label{fig:BOS1}
\end{figure}

For clarification I have highlighted only the stable neighbourhood with respect to the PNE \textit{(Fight,Fight)} in figure \ref{fig:BOS2a}. Also, notice that not all points in the stable region converge to the corresponding PNE. For an example refer to example \ref{fig:BOS2b}. While the PNE \textit{(Fight,Fight)} is attracting for all initial strategies that are above the diagonal between \textit{(Fight,Ballet)} and \textit{(Ballet,Fight)}, the PNE \textit{(Ballet,Ballet)} is attracting for all initial strategies below that diagonal. We can conclude that the stable neighbourhood is not necessarily equal to the attracting neighbourhood in general. \\

The question might arise whether the fully mixed Nash equilibrium can be stable as well. Even though there is a stable region for the MNE as depicted in \ref{fig:BOS3a}, we cannot find a neighbourhood for the MNE such that the inequality of the stability definition (\ref{def:stability}) holds for all strategies within the neighbourhood. Intuitively, no matter how far we zoom in to the MNE, we cannot draw a circle around it such that all points within the circle are blue as illustrated in figure \ref{fig:BOS3b}. Therefore except from the perfect diagonal between \textit{(Fight,Ballet)} and \textit{(Ballet,Fight)} the algorithms never converges towards the interior Nash equilibrium. The same behavior was observed for POGA. That is align with proposition \ref{prop:noInteriorStable}, stating that no interior point can be asymptotically stable under \ref{equ:FTRL}. 

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/BattleOfSexes3.png}
    \caption{stable neighbourhood w.r.t \textit{(Fight,Fight)}}
    \label{fig:BOS2a}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/BattleOfSexes4.png}
    \caption{$x_{1}^0 = (0.3,0.7)$, $x_{2}^0 = (0.65,0.35)$, $T = 200$}
    \label{fig:BOS2b}
\end{subfigure}
\caption{EGA in Battle of Sexes, $\gamma = 0.1$}
\label{fig:BOS2}
\end{figure}

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/BattleOfSexes6.png}
    \caption{stable neighbourhood w.r.t interior equilibrium}
    \label{fig:BOS3a}
\end{subfigure}%
\begin{subfigure}{.51\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/BattleOfSexes5.png}
    \caption{zoomed in to the interior equilibrium}
    \label{fig:BOS3b}
\end{subfigure}
\caption{The interior equilibrium is not asymptotically stable under EGA in Battle of Sexes}
\label{fig:BOS3}
\end{figure}


\subsection{Intersection Game}\label{subsection:intersectionGame}

Let us revisit the Intersection game from subsection \ref{subsection:CEandCCE}. The game involves two car drivers that need to cross an intersection without a crash. They can either \textit{Stop} or \textit{Go}. The driver's payoff is straightforward as in table \ref{tab:payoffIntersection}. 

\begin{table}[H]\centering
\setlength{\extrarowheight}{2pt}
\begin{tabular}{cc|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$Stop$}  & \multicolumn{1}{c}{$Go$} \\\cline{3-4}
  & $Stop$ & $0,0$ & $0,1$ \\\cline{3-4}
  & $Go$ & $1,0$ & $-100,-100$ \\\cline{3-4}
\end{tabular}\caption{\label{tab:payoffIntersection}payoff matrix Intersection game}
\end{table}

Similar to the Battle of Sexes, the game has two pure Nash equilibria, namely \textit{(Stop, Stop)} and \textit{(Go,Go)}, and a single fully mixed Nash equilibrium where both drivers choose to \textit{Stop} with probability $100/101$ and \textit{Go} with probability $1/101$. To sum up, we have the following Nash equilibria.

\begin{description}\centering
    \item $x^{*} = (Go,Go) \qquad \textit{strict }\text{PNE}$
    \item $x^{*} = (Stop,Stop) \qquad \textit{strict }\text{PNE}$
    \item $x_{1}^* = x_{2}^* = (100/101,1/101) \qquad \text{MNE}$
\end{description}

Again it is easy to check that both PNE are strict and therefore stable states (proposition \ref{prop:StrictStableEquivalent}). In figure \ref{fig:IntersectionGame1a}, the stable neighbourhoods for both PNE are colored. We can see that both PNE are indeed locally stable states. Like expected, both no-regret algorithms converge locally to the corresponding PNE (proposition \ref{prop:localConvergence}). In fact, both algorithms converge to the PNE that is the "closest" one from the initial strategy, just like in Battle of Sexes, see figure \ref{fig:IntersectionGame1a}. So the attracting regions are again divided by the diagonal between \textit{(Stop,Stop)} and \textit{(Go,Go)}. \\

Note that the MNE denoted by the star in the top right corner is indeed a fully mixed NE even though it looks like a PNE. The figure might be misleading as it seems the algorithm converges to the MNE. Even though the MNE seems to be attracting, both algorithms eventually converge to one of the strict PNE for all initial strategies. I have plotted a single trajectory using EGA in figure \ref{fig:IntersectionGame1b} to clarify that. Interestingly, the attracting neighbourhood contains initial strategies that are not included in the stable neighbourhood. So, in contrast to Battle of Sexes, the attracting neighbourhood is not a subset of the stable neighbourhood. An example for such an initial strategy is depicted in the same figure \ref{fig:IntersectionGame1b}.

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Intersection4.png}
    \caption{stable neighbourhood w.r.t \textit{(Go,Stop)} in blue and w.r.t to \textit{(Stop,Go)} in light green}
    \label{fig:IntersectionGame1a}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Intersection5.png}
    \caption{$x_{1}^0 = (0.6,0.4)$, $x_{2}^0 = (0.8,0.2)$, \\ $T = 200$}
    \label{fig:IntersectionGame1b}
\end{subfigure}
\caption{EGA behavior in the Intersection game, $\gamma = 0.1$}
\label{fig:IntersectionGame1}
\end{figure}


Just like in Battle of Sexes, we cannot find a neighbourhood for the MNE such that the equation of the stability definition \ref{def:stability} is fulfilled. As we zoom in to the MNE again, we cannot draw a circle around the MNE such that all points within the circle are colored. The zoomed-in plot is analogue to \ref{fig:BOS3b}. The same observations were made for POGA. 


\subsection{Coordination Game}\label{subsection:coordinationGame}

The behavior of the Coordination game under no-regret dynamics has already been studied in \cite{jafari} but other no-regret algorithms than EGA and OPGA were used. As the name suggests, both players aim to cooperate, see table \ref{tab:payoffCoordination3x3}.  \\

\begin{table}[H]\centering
\setlength{\extrarowheight}{2pt}
\begin{tabular}{cc|c|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$L$}  & \multicolumn{1}{c}{$C$}  & \multicolumn{1}{c}{$R$} \\\cline{3-5}
            & $T$ & $3,3$ & $0,0$ & $0,0$ \\ \cline{3-5}
            & $M$ & $0,0$ & $2,2$ & $0,0$ \\\cline{3-5}
            & $B$ & $0,0$ & $0,0$ & $1,1$ \\\cline{3-5}
\end{tabular}\caption{\label{tab:payoffCoordination3x3}payoff matrix Coordination game}
\end{table}

There are three pure Nash equilibria and multiple fully mixed Nash equilibria. As we have seen in the previous examples, fully mixed Nash equilibria are not asymptotically stable and therefore not learnable in general-sum games under no-regret dynamics. For that reason, we will neglect interior equilibria from now on. Instead, let us consider the following three PNE.

\begin{description}\centering
    \item $x^{*} = (T,L) \qquad \textit{strict }\text{PNE}$
    \item $x^{*} = (M,C) \qquad \textit{strict }\text{PNE}$
    \item $x^{*} = (B,R) \qquad \textit{strict }\text{PNE}$
\end{description}

Obviously all of them are strict PNE as any unilateral deviation from an PNE results in a decrease in payoff. Note that \textit{(B,R)} is \textit{pareto dominated} by \textit{(M,C)} which is once again \textit{pareto dominated} by \textit{(T,L)}, so \textit{(T,L)} is \textit{pareto optimal}. Refer to section \ref{section:notationAndDefinitionsGames} to recall pareto optimality. \\

One might assume that for any general-sum game that is not zero-sum no-regret algorithms do not converge as we observed in the Shapley Game in subsection \ref{subsection:shapleyGame}. However, in the Coordination game, I found convergence to one of the above PNE for all initial strategies. \\ 

I have randomized the players' initial strategies and actually most of the time both algorithms converged to the \textit{pareto optimal} PNE \textit{(T,L)} (figure \ref{fig:Coordination3x3a}). Less often I found convergence to the PNE \textit{(M,C)} (figure \ref{fig:Coordination3x3b}) and even less often to the PNE \textit{(B,R)} (figure \ref{fig:Coordination3x3c}). \\ 

Unfortunately, I could not find a pattern for which initial strategy the algorithms converge to a specific PNE. However, the fact that most of the time, it converges to \textit{(T,L)} might probably have something to do with its \textit{pareto optimality}. For a relative frequency distribution, I have empirically observed, see table \ref{tab:frequencies}. \\

\begin{table}[H]
\centering
\captionsetup{justification=centering}
 \begin{tabular}{||c c c||} 
 \hline
 \textit{(T,L)} & \textit{(M,C)} & \textit{(B,R)} \\ [0.5ex] 
 \hline\hline
 $0.64$ & $0.28$ & $0.08$ \\ [1ex] 
 \hline
 \end{tabular}\caption{\label{tab:frequencies}relative frequencies of convergence in the Coordination game, \\
 sampled $10000$ random initial strategies}
\end{table}

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Coordination3x3-1.png}
    \caption{convergence to \textit{(T,L)}}
    \label{fig:Coordination3x3a}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Coordination3x3-2.png}
    \caption{convergence to \textit{(M,C)}}
    \label{fig:Coordination3x3b}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Coordination3x3-3.png}
    \caption{convergence to \textit{(B,R)}}
    \label{fig:Coordination3x3c}
\end{subfigure}%
\caption{EGA behavior in the Coordination game, $\gamma = 0.1$}
\label{fig:Coordination3x3}
\end{figure}


The reason why both algorithms converge to Nash equilibria in the Coordination game and diverge in the Shapley Game is that there exists no strict NE in the Shapley Game but only an interior equilibrium. As we have concluded in chapter \ref{chapter:literatureReview} only strict NE survive under no-regret dynamics, which means that in games where no strict NE exists, we need to expect that the induced sequence of play diverges in general, as it did in the Shapley Game. Note that the empirical frequency of play might still converge even though no strict NE exists as we observed in the two-player zero-sum games Matching Pennies and Rock Paper Scissors. 


\section{Weak Pure Nash Equilibria}\label{section:WeakPureNashEquilibria}

Lastly, I would like to address games with a pure weak Nash equilibrium. As we have seen before, the trajectories of both algorithms never converge to fully mixed Nash equilibria which are weak equilibria per definition. That goes align with proposition \ref{prop:noInteriorStable} stating that no interior equilibrium can be asymptotically stable under \ref{equ:FTRL}. Nevertheless, games can be constructed to have pure weak Nash equilibria. When there is another strict PNE besides that, the strict one is locally attracting. Interestingly, I found convergent behavior for initial strategies "close" to the weak PNE. However, they do not converge to the weak PNE but rather somewhere to the boundary of the simplex where one player chooses a pure strategy while the other plays a mixed strategy. 

\subsection{Strict and Weak 2x2}\label{subsection:StrictAndWeak2x2}

Consider the following 2x2 payoff matrix in table \ref{tab:payoffStrictAndWeak2x2}.

\begin{table}[H]\centering
\setlength{\extrarowheight}{2pt}
\begin{tabular}{cc|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$H$}  & \multicolumn{1}{c}{$T$} \\\cline{3-4}
  & $H$ & $2,3$ & $1,2$ \\\cline{3-4}
  & $T$ & $1,2$ & $2,2$ \\\cline{3-4}
\end{tabular}\caption{\label{tab:payoffStrictAndWeak2x2}payoff matrix strict and weak pure Nash equilibria 2x2}
\end{table}

The game yields one mixed and two pure Nash equilibria. As the MNE is again not asymptotically stable we will focus on the two PNE. 

\begin{description}\centering
    \item $x^{*} = (H,H) \qquad \textit{strict }\text{PNE}$
    \item $x^{*} = (T,T) \qquad \textit{weak }\text{PNE}$
\end{description}

Let us first look at \textit{(H,H)}. It is strict in the sense of definition \ref{def:strictNE} as any unilateral deviation leads to a strict decrease in payoff. For instance, if the row player expects the column player to play \textit{H} then deviating from \textit{H} to \textit{T} would lead to a reduced payoff from $2$ to $1$. Similarly, expecting the row player to play \textit{H}, the column player's payoff decreases from $3$ to $2$ if the column player deviates from \textit{H} to \textit{T}. Therefore \textit{(H,H)} is a strict PNE. \\

The strategy profile \textit{(T,T)} on the other hand, is weak. A PNE is called weak when no player has the incentive to deviate unilaterally. However, if they deviate, they do not necessarily reduce their payoff, or equivalently, there is more than one unique best response to the PNE. In the specific game above \textit{(T,T)} is weak because expecting the row player to play \textit{T} the column player can deviate from \textit{T} to \textit{H} without reducing its payoff as $2 = 2$. Note that \textit{(T,T)} is still a PNE as the payoff also does not strictly increase when deviating. \\

Now I would like to validate the results from chapter \ref{chapter:literatureReview} that only strict PNE survive under no-regret dynamics. For the strict PNE \textit{(H,H)} I found local stability as depicted by the blue region in figure \ref{fig:2x2Weak1}. As expected, both algorithms converge to the strict PNE locally.

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak1.png}
    \caption{POGA}
    \label{fig:Weak1a}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak2.png}
    \caption{EGA}
    \label{fig:Weak1b}
\end{subfigure}
\caption{vector field with stable neighbourhood w.r.t the strict PNE \textit{(H,H)} colored in blue}
\label{fig:2x2Weak1}
\end{figure}

A closer look at the weak PNE \textit{(T,T)} shows that it is not stable in the sense of definition \ref{def:stability}. There are always strategies in the neighbourhood of the weak PNE that did not fulfill the inequality of the definition. Especially strategies profile where the row player chooses the pure strategy \textit{T}, there are "gaps" that were not stable for the weak PNE, no matter how much we zoom in, see figure \ref{fig:Weak2b}. Blue points indicate strategy profiles for which the inequality from the stability definition holds. This observation fits proposition \ref{prop:StrictStableEquivalent} saying that only strict PNE are stable. The same results were found for POGA. 

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak3.png}
    \caption{stable neighbourhood w.r.t \textit{(T,T)}}
    \label{fig:Weak2a}
\end{subfigure}%
\begin{subfigure}{.52\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak4.png}
    \caption{zoomed in to \textit{(T,T)}}
    \label{fig:Weak2b}
\end{subfigure}
\caption{The weak PNE \textit{(T,T)} is not stable under EGA}
\label{fig:2x2Weak2}
\end{figure}

The vector fields might be misleading, though, as it looks like the EGA algorithm steps outside the feasible probability simplex. However, a closer examination showed that for some initial strategies that are locally close to the weak PNE, the EGA algorithm converges towards the "left wall". An example trajectory for that phenomenon is shown in figure \ref{fig:Weak3a}. No matter how many iterations were used, the EGA algorithm did not change its direction. Moving the initial strategy slightly closer towards the strict PNE, however, yields convergence towards the strict equilibrium as illustrated in \ref{fig:Weak3b}. Again, the same holds for POGA. \\

\begin{figure}[ht]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak5.png}
    \caption{$x_{1}^0 = (0.5,0.5)$, $x_{2}^0 = (0.1,0.9)$, $T = 200$}
    \label{fig:Weak3a}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak6.png}
    \caption{$x_{1}^0 = (0.5,0.5)$, $x_{2}^0 = (0.2,0.8)$, $T = 200$}
    \label{fig:Weak3b}
\end{subfigure}
\caption{convergent behavior using EGA, $\gamma = 0.1$}
\label{fig:2x2Weak3}
\end{figure}

So indeed, the strict and therefore stable PNE is also locally attracting (proposition \ref{prop:localConvergence}). Nevertheless, even though there exists a unique strict PNE, as in the Prisoner's Dilemma, this game shows that no-regret dynamics do not necessarily converge to it globally. It seems like the existence of the weak PNE is disrupting the convergence to the strict PNE. Also, it is worth mentioning that for no initial strategy, I have found convergence to the weak PNE but rather convergence towards the "left wall". I came to the same conclusions for both algorithms. \\

In future research, it might be interesting to look at these strategies on the "left wall" more closely. A reasonable explanation for this behavior could be that the underlying probability distributions are correlated or even coarse correlated equilibria.


\subsection{Strict and Weak 3x3}\label{subsection:StrictAndWeak3x3}

The next game is a 3x3 general-sum game with two strict and one weak pure Nash equilibrium. There are also multiple fully mixed Nash equilibria. However, they are neglected again as the sequence of play never converges to one of them for the very same reason that interior states cannot be asymptotically stable (proposition \ref{prop:noInteriorStable}). Consider the 3x3 payoff matrix described in table \ref{tab:payoffStrictAndWeak3x3}. 

\begin{table}[H]\centering
\setlength{\extrarowheight}{2pt}
\begin{tabular}{cc|c|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A$}  & \multicolumn{1}{c}{$B$}  & \multicolumn{1}{c}{$C$} \\\cline{3-5}
            & $X$ & $2,3$ & $1,2$ & $1,1$ \\ \cline{3-5}
            & $Y$ & $1,1$ & $2,1$ & $3,2$ \\\cline{3-5}
            & $Z$ & $1,2$ & $2,2$ & $2,1$ \\\cline{3-5}
\end{tabular}\caption{\label{tab:payoffStrictAndWeak3x3}payoff matrix strict and weak pure Nash equilibria 3x3}
\end{table}

\begin{description}\centering
    \item $x^{*} = (X,A) \qquad \textit{strict }\text{PNE}$
    \item $x^{*} = (Y,C) \qquad \textit{strict }\text{PNE}$
    \item $x^{*} = (Z,B) \qquad \textit{weak }\text{PNE}$
\end{description}

As mentioned above the game yields three pure Nash equilibira. One can easily check that \textit{(X,A)} and \textit{(Y,C)} are strict as they are unique best responses. However, \textit{(Z,B)} is not a unique best response for the column player. Assuming the row player chooses \textit{Z}, the column player can deviate from \textit{B} to \textit{A} without losing any payoff. The payoff for the column player stays at $2$ for that deviation. Therefore \textit{(Z,B)} is weak. \\

As far as convergence is concerned, I found similar results as in the 2x2 game discussed previously. The initial strategies were randomized. In most cases, I found convergence of both EGA and OPGA to one of the strict PNE. Figure \ref{fig:Weak3x3-1} shows an example for convergence to \textit{(X,A)} and \textit{(Y, C)}, respectively.  \\

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak3x3a.png}
    \caption{convergence to \textit{(X,A)}}
    \label{fig:Weak3x3a}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak3x3b.png}
    \caption{convergence to \textit{(Y,C)}}
    \label{fig:Weak3x3b}
\end{subfigure}
\caption{Convergent behavior for strict PNE using EGA, $\gamma = 0.1$}
\label{fig:Weak3x3-1}
\end{figure}

For non of the tested initial strategy profiles, I found convergence to neither the weak PNE \textit{(Z,B)} nor any of the fully mixed NE. However, both algorithms do converge sometimes to states that are no Nash equilibria. Figure \ref{fig:Weak3x3-2} illustrates that behavior. \\ 

Note that the initial strategies here are not too "far" from the weak PNE \textit{(Z,B)}. The behavior corresponds to the convergence towards the "left wall" from figure \ref{fig:Weak3a}. Again, these empirical findings match the general result that only strict Nash equilibria survive under no-regret dynamics.  

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak3x3-2a.png}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak3x3-2b.png}
\end{subfigure}
\caption{Convergent behavior to states that are no Nash equilibria using EGA, $\gamma = 0.1$}
\label{fig:Weak3x3-2}
\end{figure}

\subsection{Weak 2x2}\label{subsection:Weak 2x2}

Lastly, we consider a game with no strict but a weak pure Nash equilibrium. Consider the following payoff matrix in table \ref{tab:payoffWeak2x2}. 

\begin{table}[H]\centering
\setlength{\extrarowheight}{2pt}
\begin{tabular}{cc|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$H$}  & \multicolumn{1}{c}{$T$} \\\cline{3-4}
  & $H$ & $1,1$ & $1,2$ \\\cline{3-4}
  & $T$ & $0,2$ & $2,2$ \\\cline{3-4}
\end{tabular}\caption{\label{tab:payoffWeak2x2}payoff matrix weak pure Nash equilibrium 2x2}
\end{table}

Note that this time there is no strict PNE. However, \textit{(T,T)} is weak because it is not the unique best response for both players. For example, assuming the row player chooses \textit{T}, then the column player can deviate from \textit{T} to \textit{H} without reducing its utility. Also, there is a mixed Nash equilibrium where both players select each action equally likely. 

\begin{description}\centering
    \item $x^{*} = (T,T) \qquad \textit{weak }\text{PNE}$
    \item $x_{1}^* = (1/2,1/2) \qquad x_{2}^* = (1/2,1/2) \qquad \text{MNE}$
\end{description}

Consider the following two figures \ref{fig:Weak2x2-1} and \ref{fig:Weak2x2-2}. 

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak2x2-1.png}
    \caption{POGA}
    \label{fig:Weak2x2-1a}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak2x2-2.png}
    \caption{EGA}
    \label{fig:Weak2x2-1b}
\end{subfigure}
\caption{vector field in a game with a weak PNE}
\label{fig:Weak2x2-1}
\end{figure}

\begin{figure}[H]
\captionsetup{justification=centering}
\centering
\begin{subfigure}{.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak2x2-3.png}
    \caption{global perspective}
    \label{fig:Weak2x2-2a}
\end{subfigure}%
\begin{subfigure}{.53\textwidth}
    \centering
    \includegraphics[width=\textwidth]{logos/Weak2x2-6.png}
    \caption{zoomed in to \textit{(T,T)}}
    \label{fig:Weak2x2-2b}
\end{subfigure}
\caption{stable neighbourhood with respect to \textit{(T,T)}}
\label{fig:Weak2x2-2}
\end{figure}

Interestingly, the plots suggest that there is no convergent behavior to Nash for any initial strategy. Neither the interior nor the weak PNE is attracting, see figure \ref{fig:Weak2x2-1}. Instead, both algorithms converge to the boundary where only one player selects the pure strategy \textit{T}. \\

When we look at trajectories, we have similar behavior as described previously in figure \ref{fig:Weak3a}. Considering figure \ref{fig:Weak2x2-2a} it appears like the weak PNE is globally stable. However, as we zoom in, we find these "gaps" on the boundary indicating that the weak equilibrium is not stable, see figure \ref{fig:Weak2x2-2b}.







