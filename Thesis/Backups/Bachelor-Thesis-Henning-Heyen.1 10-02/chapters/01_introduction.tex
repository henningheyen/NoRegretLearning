
\chapter{Introduction}\label{chapter:introduction}

\begin{comment}
\begin{itemize}
    \item So far, there is no comprehensive characterization of games that are “learn- able,” but there are some important results. For example, it is well-known that no-regret dynamics converge to a coarse correlated equilibrium in arbitrary fi- nite games [17,26,15,12]. Coarse correlated equilibria (CCE) encompass the set of correlated equilibria (CE) of a finite game. The latter is a nonempty convex polytope which in turn contains the convex hull of the game’s Nash equilibria such that we get NE subset CE subset CCE. (ComputingBNE, p.3)
    \item investigate the question whether NE is learnable via nor regret dynamics \cite{jafari} Introduction
    \item What is the outcome of multi agent learning via no regret algorithms in repeated games? A learning algorithm is said to exhibit no regret iff average payoffs that are achieved by the algorithm exceed tha payoffs that could be achieved by any fixed strategy. in the limit. \cite{jafari} Introduction
    \item best response dynamics like fictitious play does not converge to NE in general  because rational play yields deterministic play. Therefore rational play can not possibly converge to NE in games where no PNE exist. In contrast no regret dynamics are recipes by which to update probabilities that agents assaign to actions could potentially learn MNEs. 
    \item under FoReL only \textit{strict Nash equilibria} survive. 
\end{itemize}
\end{comment}



