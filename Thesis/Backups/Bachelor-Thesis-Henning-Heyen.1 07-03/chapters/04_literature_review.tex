
\chapter{Literature Review}\label{chapter:literatureReview}

This chapter aims to give an overview of important results in no-regret dynamics applied in finite games. First we will discuss some general game theoretic findings that motivate the usage of no-regret dynamics in game theory and then summarize results considering the convergence behavior under no-regret dynamics in finite games. \\

\section{General Results}\label{section:generalResults}

John Nash famously proved in 1950 that for every finite game with mixed extension there exists at least one mixed Nash equilibrium (MNE) \cite{nash}. So the set of MNE is not empty. This theorem became known as \textit{Nash's Theorem}. Another important result is that there exists no polynomial-time algorithm for computing Nash equilibria. In fact,  finding a Nash equilibrium in finite games is \textit{PPAD}-complete. That was first shown by by Daskalakis, Goldberg and Papadimitriou  with at least 3 players \cite{daskalakis} and later extended by Chen and Deng to 2 players \cite{chen}. This rises the question whether Nash equilibria are learnable at all. \\

No-regret algorithms are recipes by which players update probabilities that they assign to actions. So if all players employ a no-regret update policy they could potentially learn, that means converge to mixed Nash equilibria.  Convergence can be formulated in various ways. Lets first consider the players' empirical frequency of play, i.e time-averaged selected strategies. Later we consider the convergence of the actual sequence trajectories, last-iterates in short.\\

It was shown that under no-regret dynamics the empirical frequency of play converges to the game's set of coarse correlated equilibria (CCE) \cite{flokas}, a rather weak game theoretic solution concept. No-regret learning may cycle and weight only strictly dominated strategies \cite{mertikopoulos}. In fact, the \textit{impossibility result} by Hart and Mas-Colell states that there exist no uncoupled dynamics which guarantee Nash convergence \cite{hart}. No-regret dynamics are, by construction, uncoupled in the sense that a player’s update rule does not explicitly depend on the payoffs of other players. Therefore the \textit{impossibility result} precludes Nash convergence of no-regret learning. This is consistent with the numerous negative complexity results for finding a Nash equilibrium \cite{chen, daskalakis}. \\


\section{Sufficient Conditions for Nash Convergence}\label{section:SufficientConditionsForNash Convergence}

Despite these negative results, in empirical experiments Nash convergence was observed under no-regret algorithms for some games. In the following, I aim to provide an overview of sufficient conditions under which no-regret learning converges A NE. In chapter \ref{chapter:simulations} I try to give empirical evidence and visualize the results. \\

Similar to this thesis, in 2001 Jafari, Greenwald, Gondek and Ercal studied the behaviour of a concrete no-regret algorithm, namely Hedge, on simple finite games. They found that the algorithm's induced sequence of play converges to NE in dominance-solvable games such as the Prisoner's Dilemma, a game where a unique dominant strategy pure Nash equilibrium (PNE) exists \cite{jafari}. They additionally suggest that in two player zero games the empirical frequency of play converges to fully mixed NE under no-regret dynamics by employing the algorithm the games Rock Paper Scissors and Matching Pennies. However, in the Shapley Games, a general-sum 3x3 game, the Hedge algorithm exhibits non convergent exponential cycling behavior \cite{jafari} which suggest that in general sum games no-regret algorithms fail to converge to NE in general.\\

Later in 2016 Sandholm and Mertikopoulos formally proved the these findings \cite[Theorem 4.1 and Theorem 6.1]{sandholm}.

\begin{proposition}\label{prop:dominantedStrategiesExtinct}
    Under FTRL iteratively dominated strategies become extinct
\end{proposition}

\begin{proposition}\label{prop:empiricalFrequencyConvergence}
    Under FTRL the empirical frequency of play converges to Nash in two player zero-sum games with interior equilibria
\end{proposition}

Considering the actual trajectories that players take we know that in zero sum games that admit an interior Nash equilibrium are non-convergent for all initial strategy profiles other than the equilibrium. More specifically for 2x2 zero sum games, even though the time averaged strategies converge under \ref{equ:FTRL} dynamics, the actual sequence of strategies are repelled away from the equilibrium and will eventually move towards the boundary of the probability simplex \cite[Theorem 1]{bailey}.

So far we have seen that in zero sum games with interior equilibrium trajectories under \ref{equ:FTRL} diverge. More recent studies have shown that in fact, only strict Nash equilibria survive under \ref{equ:FTRL} dynamics \cite{flokas}. It turned out that strict NE are so called \textit{stable} states. Lets introduce the notion of stable states \cite[Def. 2.3]{mertikopoulos}. 

\begin{definition}\label{def:stability}
    A state $x^* \in \mathcal{X}$ is called \textit{variational stable} (or simply stable) if there exists a neighborhood $U$ of $x^*$ such that 
    \[\langle v(x),x-x^*\rangle \le 0 \qquad \forall x \in U\]
\end{definition}

with equality if and only if $x = x^*$. In particular, if $U$ can be taken to be all of $\mathcal{X}$, we say that $x^*$ is \textit{globally variationally stable} (or \textit{globally stable} for short). In other words, if $x^*$ is stable, then for all $x$ in the neighborhood of $x^*$ the players’ individual payoff gradients $v(x)$ “point towards” $x^*$ in the sense that the angle between $x^* - x$ and $v(x)$ is acute. Multiple implications can be concluded from that.\\

It was shown that no interior point, and therefore no \textit{fully mixed Nash equilibrium}, can be asymptotically stable under \ref{equ:FTRL} dynamics \cite[Theorem 1]{flokas}.  

\begin{proposition}\label{prop:noInteriorStable}
    A fully \textit{mixed NE} cannot be asymptotically stable under \ref{equ:FTRL}
\end{proposition}

Actually only strict Nash equilibria can be stable under \ref{equ:FTRL} \cite[Theorem 2]{flokas}. In fact, a stable state is equivalent to a strict Nash equilibrium \cite[Prop. 5.2]{mertikopoulos}

\begin{proposition}\label{prop:StrictStableEquivalent}
    The following are equivalent
    \begin{enumerate}
        \item $x^*$ is stable
        \item $x^*$ is a strict Nash equilibrium
    \end{enumerate}
\end{proposition}
    
In particular if $x^*$ is \textit{globally stable} then $x^*$ is a unique Nash equilibrium \cite[Prop.2.5]{mertikopoulos}.

\begin{proposition}\label{prop:GloballyStableUniqueNE}
    If $x^*$ is globally stable, it is the game’s unique Nash equilibrium.
\end{proposition}

As shown in \cite[Theorem 4.7]{mertikopoulos} and \cite[Theorem 4.11]{mertikopoulos} respectively we furthermore have that when no-regret dynamics are employed the following two propositions hold.

\begin{proposition}\label{prop:globalConvergence}
    The induced sequence of play converges globally to a \textit{globally stable} equilibrium with probability $1$
\end{proposition}

\begin{proposition}\label{prop:localConvergence}
    If $x^*$ is stable then it is locally attracting with high probability
\end{proposition}


In the next chapter I would like to give empirical evidence for all the findings discussed here. I will run two concrete no-regret algorithms, on simple two player games and visualize their convergence behavior. 
